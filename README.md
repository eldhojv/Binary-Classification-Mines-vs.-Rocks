# Binary Classification (Mines vs. Rocks)

[![Hex.pm](https://img.shields.io/hexpm/l/plug.svg)](https://github.com/junaidfiaz143/Binary-Classification-Mines-vs.-Rocks/blob/master/LICENSE) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/Django.svg)](https://github.com/junaidfiaz143/Binary-Classification-Mines-vs.-Rocks/blob/master/LICENSE)


[![Twitter URL](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Binary%20Classification%20using%20multiple%20Keras%20APIs%20model%20https://github.com/junaidfiaz143/Binary-Classification-Mines-vs.-Rocks&&via=junaidfiaz143&hashtags=ML,TF,KERAS,developer)

In this project you will discover how to effectively use the Keras library in your machine learning project by working through a binary classification project step-by-step.

## Getting Started

### Description of the Dataset
The dataset we will use in this tutorial is the Sonar dataset.

This is a dataset that describes sonar chirp returns bouncing off different services. The 60 input variables are the strength of the returns at different angles. It is a binary classification problem that requires a model to differentiate rocks from metal cylinders.

You can learn more about this dataset on the UCI Machine Learning repository:
https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)

It is a well-understood dataset. All of the variables are continuous and generally in the range of 0 to 1. The output variable is a string “M” for mine and “R” for rock, which will need to be converted to integers 1 and 0.

### What we achieved doing this Project for the Navy:
In this post, you discovered the three API styles used in Keras Deep Learning library in Python.

You learned how you can work through a binary classification problem step-by-step with Keras, specifically:

+	How to load and prepare data for use in Keras.
+	How to create a baseline neural network model.
+	How to evaluate a Keras model using scikit-learn and stratified k-fold cross validation.
+	How data preparation schemes can lift the performance of your models.
+	How experiments adjusting the network topology can lift model performance.

### Prerequisites

What things you need to install the software and how to install them

```
puthon IDE
jupyter notebook
```

## Deployment

Add additional notes about how to deploy this on a live system

## Built With

* [python](https://www.python.org/) - Programming Language
* [tensorflow](https://www.tensorflow.org/) - TensorFlow is an open-source machine learning library for research and production
* [keras](https://keras.io/) - Keras is a high-level neural networks API
* [sklearn](http://scikit-learn.org/stable/documentation.html) - Scikit-learn is a free software machine learning library for the Python 
* [numpy](http://www.numpy.org/) - NumPy is the fundamental package for scientific computing
* [pandas](https://pandas.pydata.org/) - Pandas is a software library used for data manipulation and analysis

## Authors

* **M.Junaid Fiaz** - *Initial work* - [JD](https://github.com/junaidfiaz143)
<!-- 
See also the list of [contributors](https://github.com/your/project/contributors) who participated in this project. -->

## License

This project is licensed under the APACHE License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Hat tip to anyone whose code was used
* Inspiration
* etc

